apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  labels:
    app: user-service
    tier: backend

spec:
  replicas: 2

  selector:
    matchLabels:
      app: user-service

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0   # Así evitamos downtime durante despliegues

  template:
    metadata:
      labels:
        app: user-service
        tier: backend

      # Prometheus scrapea métricas directamente desde el pod

      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3001"
        prometheus.io/path: "/metrics"

    spec:
      
      # Damos tiempo a que termine requests en vuelo antes de apagar el pod

      terminationGracePeriodSeconds: 30

      # Ejecutamos como usuario no-root por seguridad

      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001

      # Init Container: Espera a que Redis esté disponible antes de arrancar
      # Esto elimina el restart inicial que ocurre cuando user-service arranca antes que Redis esté ready
      
      initContainers:
        - name: wait-for-redis
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              echo "Waiting for Redis to be ready..."
              until nc -z redis 6379; do
                echo "Redis is not ready yet, sleeping 2s..."
                sleep 2
              done
              echo "Redis is ready! Starting user-service..."
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL

      containers:
        - name: user-service
          image: ghcr.io/vipmed-technology/user-service:latest
          imagePullPolicy: Always

          # FIX BUG 6:
          # El contenedor escucha en el puerto 3001, que es el puerto configurado en la aplicación, y que debe coincidir con el puerto definido en el Service para que la comunicación funcione correctamente.

          ports:
            - containerPort: 3001
              name: http

          env:
            
            # Configuración no sensible desde ConfigMap

            - name: PORT
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: USER_SERVICE_PORT

            - name: NODE_ENV
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: NODE_ENV

            - name: LOG_LEVEL
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: LOG_LEVEL

            - name: APP_VERSION
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: APP_VERSION

            # Password de Redis desde Secret

            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: app-secrets
                  key: redis-password

            # URL completa de Redis construida con la password
            # FIX BUG 4: 
            # El hostname correcto dentro del cluster es redis, ademas apunta al service llamado redis en la linea de codigo value: "redis://:$(REDIS_PASSWORD)@redis:6379" Porque ahí se usa el hostname correcto.
            # No usa localhost
            # No está usando 127.0.0.1
            # No está usando redis-service

            - name: REDIS_URL
              value: "redis://:$(REDIS_PASSWORD)@redis:6379"

          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "500m"
              memory: "256Mi"

          # Liveness probe: el proceso sigue vivo?
          # Si falla → Kubernetes reinicia el contenedor
          # FIX BUG 5:
          # Kubernetes permite 3 fallos seguidos antes de reiniciar el contenedor, lo que da margen para manejar picos temporales o problemas momentáneos sin causar reinicios innecesarios.
          # El fix del bug esta en livenessProbe en failureThreshold: 3, que es un valor razonable para aplicaciones Node.js que pueden experimentar picos de CPU ocasionales durante el procesamiento de solicitudes.
          # El fix del bug tambien esta en readinessProbe en failureThreshold: 3, que es un valor razonable para aplicaciones Node.js que pueden experimentar picos de CPU ocasionales durante el procesamiento de solicitudes, evitando marcar el servicio como no listo por problemas momentáneos.
          # El fix del bug tambien esta en startupProbe en failureThreshold: 12, que da un margen amplio para que la aplicación termine de arrancar, especialmente si tiene tareas de inicialización que pueden tardar más de lo normal, evitando reinicios prematuros durante el arranque inicial

          livenessProbe:
            httpGet:
              path: /health/live
              port: 3001
            initialDelaySeconds: 15
            periodSeconds: 20
            timeoutSeconds: 5
            failureThreshold: 3

          # Readiness probe: puede recibir tráfico?
          # Si Redis cae, deja de recibir requests pero no se reinicia

          readinessProbe:
            httpGet:
              path: /health/ready
              port: 3001
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 3

          # Startup probe: le da margen al pod en el arranque inicial

          startupProbe:
            httpGet:
              path: /health/live
              port: 3001
            initialDelaySeconds: 5
            periodSeconds: 5
            failureThreshold: 12   # 12 * 5s = 60s máximo

          # Hardening extra del contenedor

          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - ALL

      restartPolicy: Always